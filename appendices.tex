% -*- Mode: latex -*- %

\subsection{Proof of Theorem~\ref{thm:LAN1}
\label{proof:thm:LAN1}
}
The log-probability mass distribution of $(B_1,\ldots,B_n)$ is given by
\begin{align*}
& \log \Prob_\theta(b_1,\ldots,b_n) = \sum_{i=1}^n \left( \frac{b_i+1}{2} \log  \Prob(X_i\in A_i) + 
\frac{1-b_i}{2} \log \Prob(X_i\in A_i) \right), \quad b_i \in \{-1,1\}, \quad i=1,\ldots,n. 
\end{align*}
Consequently, 
\begin{align}
& \log \frac{ \Prob_{\theta + \frac{h}{\sqrt{n}}}(b_1,\ldots,b_n)} { \Prob_\theta (b_1,\ldots,b_n) } = \sum_{i=1}^n    \frac{b_i+1}{2} 
\log \frac{\Prob_{\theta+\frac{h}{\sqrt{n}}}(X_i \in A_i)}{\Prob_{\theta}(X_i \in A_i)} + 
\sum_{i=1}^n  \frac{1-b_i}{2} 
\log \frac{\Prob_{\theta+\frac{h}{\sqrt{n}}}(X_i \notin A_i)}{\Prob_{\theta}(X_i \notin A_i)}. 
\label{eq:LAN_proof1}
\end{align}
For each $i=1,\ldots,n$, write 
\[
A_i = \bigcup_{k=1}^{K_i} \left(t_{i,2k-1},t_{i,2k} \right),
\]
where $t_{i,1}<\ldots<t_{i,K_i}$ and, with a slight abuse of notation, $t_{i,1}$ and $t_{i,K_i}$ may take the values $-\infty$ or $+\infty$, respectively. Thus
\[
\Prob_{\theta}(X_i \in A_i) = \sum_{k=1}^{K_i} (-1)^k F(t_{i,k}-\theta).
\]
In particular, since $f$ is differentible in $\theta$, $\Prob_{\theta}(X_i \in A_i)$ is twice differentiable, and we may write
\begin{align*}
\Prob_{\theta+\frac{h}{\sqrt{n}}}(X_i \in A_i)  = \Prob_{\theta} (X_i \in A_i) + \frac{d}{d\theta} \Prob_{\theta}(X_i \in A_i) \frac{h}{\sqrt{n}} + o(h), 
\end{align*}
and thus
\begin{align*}
& \log \frac{\Prob_{\theta+\frac{h}{\sqrt{n}}}(X_i \in A_i)}{\Prob_{\theta}(X_i \in A_i)} = \log \left(1 + \frac{\frac{d}{d\theta} \Prob_{\theta}(X_i \in A_i)}{\Prob_{\theta}(X_i \in A_i)}  \frac{h}{\sqrt{n}} + o(h) \right) \\
& = \frac{\frac{d}{d\theta} \Prob_{\theta}(X_i \in A_i)}{\Prob_{\theta}(X_i \in A_i)}  \frac{h}{\sqrt{n}} - \frac{h}{2n} \left( \frac{\frac{d}{d\theta} \Prob_{\theta}(X_i \in A_i)}{\Prob_{\theta}(X_i \in A_i)}  \right)^2 + o(h^2). 
\end{align*}
Similarly, we have
\begin{align*}
& \log \frac{\Prob_{\theta+\frac{h}{\sqrt{n}}}(X_i \notin A_i)}{\Prob_{\theta}(X_i \notin A_i)} \\
& = \frac{\frac{d}{d\theta} \Prob_{\theta}(X_i \notin A_i)}{\Prob_{\theta}(X_i \notin A_i)}  \frac{h}{\sqrt{n}} - \frac{h}{2n} \left( \frac{\frac{d}{d\theta} \Prob_{\theta}(X_i \notin A_i)}{\Prob_{\theta}(X_i \notin A_i)}  \right)^2 + o(h^2). 
\end{align*}
From \eqref{eq:LAN_proof1} we obtain
\begin{align*}
& \log \frac{ \Prob_{\theta + \frac{h}{\sqrt{n}}}(b_1,\ldots,b_n)} { \Prob_\theta (b_1,\ldots,b_n) }   = \frac{h}{\sqrt{n}} \sum_{i=1}^n  
\left( 
\frac{b_i+1}{2}  \frac{\frac{d}{d\theta} \Prob_{\theta}(X_i \in A_i)}{\Prob_{\theta}(X_i \in A_i)}  + 
 \frac{1-b_i}{2}  \frac{\frac{d}{d\theta} \Prob_{\theta}(X_i \notin A_i)}{\Prob_{\theta}(X_i \notin A_i)}   \right) \\
 & - \frac{h^2}{2n} 
 \sum_{i=1}^n 
\left( 
 \frac{b_i+1}{2} 
\left( \frac{\frac{d}{d\theta} \Prob_{\theta}(X_i \in A_i)}{\Prob_{\theta}(X_i \in A_i)}  \right)^2
+ 
 \frac{1-b_i}{2} \left( \frac{\frac{d}{d\theta} \Prob_{\theta}(X_i \notin A_i)}{\Prob_{\theta}(X_i \notin A_i)}  \right)^2 \right) + o(h^2) \\
\end{align*}
%
Noting that 
\[
\frac{\frac{d}{d\theta} \Prob_{\theta}(X_i \notin A_i)}{\Prob_{\theta}(X_i \notin A_i)} = \frac{-\frac{d}{d\theta} \Prob_{\theta}(X_i \in A_i)}{1-\Prob_{\theta}(X_i \in A_i)},
\]
the proof is completed by proving the following two claims:
\begin{itemize}
\item[I.] 
For $i=1,\ldots,n$ denote 
\[
U_i = \frac{B_i+1}{2}  \frac{\frac{d}{d\theta} \Prob_{\theta}(X_i \in A_i)}{\Prob_{\theta}(X_i \in A_i)}  + 
 \frac{1-B_i}{2}  \frac{-\frac{d}{d\theta} \Prob_{\theta}(X_i \in A_i)}{1-\Prob_{\theta}(X_i \in A_i)}. 
\]
Then 
\[
\frac{1}{\sqrt{n}} \sum_{i=1}^n U_i \overset{d}{\rightarrow} \Ncal\left(0, \kappa(\theta) \right). 
\]
\item[II.]
For $i=1,\ldots,n$ denote 
\[
V_i =  \frac{B_i-1}{2} 
\left( \frac{\frac{d}{d\theta} \Prob_{\theta}(X_i \in A_i)}{\Prob_{\theta}(X_i \in A_i)}  \right)^2
+ 
 \frac{1-B_i}{2} \left( \frac{\frac{d}{d\theta} \Prob_{\theta}(X_i \in A_i)}{1-\Prob_{\theta}(X_i \in A_i)}  \right)^2.
\]
Then 
\[
\frac{1}{n} \sum_{i=1}^n V_i \overset{a.s.}{\rightarrow} \kappa(\theta). 
\]
\end{itemize}
\subsubsection*{Proof of Claim I}
First note that 
\begin{align*}
\ex{U_i} & = 
 \frac{\frac{d}{d\theta} \Prob_{\theta}(X_i \in A_i)}{\Prob_{\theta}(X_i \in A_i)}   \Prob (B_i=1)   + 
 \frac{-\frac{d}{d\theta} \Prob_{\theta}(X_i \in A_i)}{1-\Prob_{\theta}(X_i \in A_i)}   \Prob (B_i=-1)  = 0. 
\end{align*}
In addition,
\begin{align*}
& \ex{ U_i^2} = 
\left( \frac{\frac{d}{d\theta} \Prob_{\theta}(X_i \in A_i)}{\Prob_{\theta}(X_i \in A_i)}  \right)^2  \Prob (B_i=1)   + 
\left( \frac{-\frac{d}{d\theta} \Prob_{\theta}(X_i \in A_i)}{1-\Prob_{\theta}(X_i \in A_i)}  \right)^2 \Prob (B_i=-1) \\
& =
 \frac{ \left(\frac{d}{d\theta} \Prob_{\theta}(X_i \in A_i) \right)^2}{\Prob_{\theta}(X_i \in A_i)} +  
  \frac{ \left(\frac{d}{d\theta} \Prob_{\theta}(X_i \in A_i) \right)^2}{1-\Prob_{\theta}(X_i \in A_i)} \\
 & =  
  \frac{ \left(\frac{d}{d\theta} \Prob_{\theta}(X_i \in A_i) \right)^2}{\Prob_{\theta}(X_i \in A_i) \left(1-\Prob_{\theta}(X_i \in A_i) \right)} 
\end{align*}
Therefore
\[
\frac{1}{n} \sum_{i=1}^n \ex{ U_i^2} = L_n(A_1,\ldots,A_n) \overset{a.s.}{\longrightarrow} \kappa(\theta)
\]
for any $\theta \in \Theta$ such that the limit above exists. We now verify that the sequence $\{ U_i,\,i=1,2,\ldots \}$ satisfies Lyaponov's condition for his version of the central limit time: for any $\delta>0$ we have that 
\begin{align*}
& \ex{ \left| U_i \right|^{2+\delta} }=
 \frac{ \left| \frac{d}{d\theta} \Prob_{\theta}(X_i \in A_i) \right|^{2+\delta}} {(\Prob_{\theta}(X_i \in A_i))^{1+\delta}} +  
  \frac{ \left|\frac{d}{d\theta} \Prob_{\theta}(X_i \in A_i) \right|^{2+\delta}} {(1-\Prob_{\theta}(X_i \in A_i))^{1+\delta}} 
\end{align*}
and
\begin{equation}
\frac{\sum_{i=1}^n\ex{\left| U_i \right|^{2+\delta}} } { \left( \sum_{i=1}^n \ex{U_i^2}  \right)^\delta} = 
\frac{ \frac{1}{n^{1+\delta}} \sum_{i=1}^n \ex{ |U_i|^{2+\delta}} }{ \left(\frac{1}{n} \sum_{i=1}^n \ex{U_i^2 } \right)^\delta}. 
\label{eq:Lyaponov}
\end{equation}
Next, we claim that there exits $\delta>0$ and $K(\delta)>0$, that are independent of $n$, such that
\begin{align}
\frac{1}{n} \sum_{i=1}^n \ex{ |U_i|^{2+\delta}}  < K(\delta) \label{eq:Lyaponov_num}
\end{align} 
for all $n$ large enough. To see this, note that
\begin{align*}
& \ex{ |U_i|^{2+\delta} }= 
 \frac{ \left| \frac{d}{d\theta} \Prob_{\theta}(X_i \in A_i) \right|^{2+\delta}} {(\Prob_{\theta}(X_i \in A_i))^{1+\delta}} +  
  \frac{ \left|\frac{d}{d\theta} \Prob_{\theta}(X_i \in A_i) \right|^{2+\delta}} {(1-\Prob_{\theta}(X_i \in A_i))^{1+\delta}}  \\
  &  = \frac{\left| \frac{d}{d\theta} \Prob_{\theta}(X_i \in A_i) \right|^{2+\delta} }
  { (\Prob_{\theta}(X_i \in A_i))^{1+\delta} (1-\Prob_{\theta}(X_i \in A_i))^{1+\delta} } 
  \left( (1-\Prob_{\theta}(X_i \in A_i))^{1+\delta} + (\Prob_{\theta}(X_i \in A_i))^{1+\delta}   \right) \\
  &  \leq \frac{\left| \frac{d}{d\theta} \Prob_{\theta}(X_i \in A_i) \right|^{2+\delta} }
  { (\Prob_{\theta}(X_i \in A_i))^{1+\delta} (1-\Prob_{\theta}(X_i \in A_i))^{1+\delta}}. 
\end{align*}
%where the last transition is because 
%\[
% \left( (1-\Prob_{\theta}(X_i \in A_i))^{1+\delta} + (\Prob_{\theta}(X_i \in A_i))^{1+\delta}  \right) \leq 1. 
%\]
We now use the fact that each $A_i$ is a finite union of intervals. Under the assumption that there exists $\delta>0$ such that $\eta^{1+\delta}(x)/f^\delta(x)$ is uniquely maximized by the origin and is non-increasing in $|x|$, Lemma~\ref{lem:bound_intervals_delta} implies
\begin{align*}
  &  \leq \frac{\left| \frac{d}{d\theta} \Prob_{\theta}(X_i \in A_i) \right|^{2+\delta} }
  { (\Prob_{\theta}(X_i \in A_i))^{1+\delta} (1-\Prob_{\theta}(X_i \in A_i))^{1+\delta}} = \frac{\left| \sum_{k=1}^{K_i} (-1)^k f(x_{i,k}-\theta) \right|^{2+\delta} }
  { \left( \sum_{k=1}^{K_i} (-1)^k F(x_{i,k}-\theta) \right)^{1+\delta} \left( 1 - \sum_{k=1}^{K_i} (-1)^k F(x_{i,k}-\theta) \right)^{1+\delta}} \\
  & \leq 4^{1+\delta}(f(0))^{2+\delta}.
\end{align*}
It follows that
\[
\frac{1}{n} \sum_{i=1}^n \ex{ |U_i|^{2+\delta}} \leq 4^{1+\delta}(f(0))^{2+\delta}, 
\]
and thus the numerator of \eqref{eq:Lyaponov}, as well as the entire expression, goes to zero. From Lyaponov's central limit theorem we obtain 
\[
\frac{1}{\sqrt{n}} \sum_{i=1}^n U_i \overset{d}{\rightarrow} \Ncal\left(0,\kappa(\theta) \right). 
\]

\subsubsection*{Proof of Claim II} 
We have:
\begin{align*}
\ex{ V_i}  & = 
 \frac{ \left(\frac{d}{d\theta} \Prob_{\theta}(X_i \in A_i) \right)^2}{\Prob_{\theta}(X_i \in A_i)}  
+ 
 \frac{ \left(\frac{d}{d\theta} \Prob_{\theta}(X_i \in A_i) \right)^2}{1-\Prob_{\theta}(X_i \in A_i)}  \\
 & = 
  \frac{ \left(\frac{d}{d\theta} \Prob_{\theta}(X_i \in A_i) \right)^2}{\Prob_{\theta}(X_i \in A_i) \left( 1-\Prob_{\theta}(X_i \in A_i) \right)}  
\end{align*}
 We conclude that:
\begin{equation} \label{eq:LAN_limit_cond}
\frac{1}{n} \sum_{i=1}^n \ex{ V_i} =   L_n(A_1,\ldots,A_n)  \to \kappa(\theta)
\end{equation}
Since the $V_i$s are independent of each other, Kolmogorov's law of large numbers implies
%(e.g. \cite[Theorem 10.2.3]{sen1994large}) 
\[
\frac{1}{n} \sum_{i=1}^n  V_i \overset{a.s.}{\longrightarrow} \kappa(\theta)
\]
for any $\theta \in \Theta$ for which the limit \eqref{eq:LAN_limit_cond} exists.
\QEDA


\subsection{Proof of Theorem~\ref{thm:non_existence}
\label{proof:thm:non_existence}
}

Let $\Xi$ be the set of points $\theta \in \Theta$ for which $\kappa(\theta) = \eta(0)$. 
%
Since $B_1,B_2,\ldots$ satisfy the conditions in Theorem~\ref{thm:LAN1}, $\theta$ is in $\Xi$ if and only if
\begin{equation}
\label{eq:non_existence_proof}
\lim_{n\to \infty} L_n(A_1,\ldots,A_n;\theta) = \eta(0). 
\end{equation}
By assumption, we have $B_i^{-1} = A_i$ where $A_i$ can be expressed as
\[
A_i = \cup_{i=1}^K (a_{i,k},b_{i,k}), 
\]
where $a_{i,1} \leq b_{i,1} \leq \ldots \leq a_{i,K}, b_{i,K}$, and $a_{i,1}$ and $b_{i,K}$ may take the values $-\infty$ and $\infty$, respectively. Denote
\[
C_i = \cup_{k=1}^{K}\{a_{i,k},b_{i,k}\}.
\]
For any $\theta$ and $\epsilon>0$, denote 
\[
S_n(\theta, \epsilon) \triangleq \left\{ i\leq n \,:\, (\theta-\epsilon,\theta+\epsilon) \cap C_i \neq \emptyset \right\}
\]
In words, $S_n$ contains all integers smaller than $n$ in which an $\epsilon$-ball around $\theta$ contains an endpoint of one of the intervals consisting $A_i$. 
%
We now claim that 
if $\theta \in \Xi$ then $\card(S_n(\theta, \epsilon))/n \to 1$. Indeed, for such $\theta$ we have
\begin{align}
& L_n(A_1,\ldots,A_n; \theta) \nonumber \\
& = \frac{1}{n} \sum_{i \in S_n(\epsilon,\theta)}  
\frac{ \left(\sum_{k=1}^{K}  f(\theta - b_{i,k})- f(\theta - a_{i,k}) \right)^2}{ \sum_{k=1}^{K} \left( F(\theta - b_{i,k})- F(\theta - a_{i,k}) \right) \left(1-\sum_{k=1}^{K} \left( F(\theta - b_{i,k})- F(\theta - a_{i,k}) \right)\right)} \nonumber \\
& 
+ \frac{1}{n}\sum_{i \notin S_n(\epsilon,\theta) } \frac{ \left(\sum_{k=1}^{K}  f(b_{i,k}-\theta) - f(a_{i,k}-\theta) \right)^2} { \sum_{k=1}^{K} \left( F(\theta - b_{i,k})- F(\theta - a_{i,k}) \right) \left(1-\sum_{k=1}^{K} \left( F(\theta - b_{i,k})- F(\theta - a_{i,k}) \right)\right)} \nonumber \\
& \overset{(a)}{\leq}
\frac{\card\left(S_n(\theta,\epsilon)\right)}{n} \eta(0) + \frac{n-\card\left(S_n(\theta,\epsilon) \right) }{n} \eta(\epsilon) 
 \label{eq:non_existence_proof1}
\end{align}
where $(a)$ follows from Lemma~\ref{lem:bound_intervals_delta} with $\delta =0$, and the fact that for $i \in S_n(\theta, \epsilon)$, 
\[
\max\left\{ \max_k \eta(b_{i,k}-\theta) , \max_k \eta(a_{i,k}-\theta)  \right\} \leq \eta(\epsilon) < \eta(0). 
\]
Unless  $\card \left(S_n(\theta, \epsilon) \right)/n \to 1$, we get that \eqref{eq:non_existence_proof1}, hence $L_n(A_1,\ldots,A_n ; \theta)$, are bounded from above by a constant that is smaller then $\eta(0)$ in contradiction to the fact that $\theta \in \Xi$. \par
For $k\in \N$, assume by contradiction that there exists $N \geq 2K + 1$ distinct elements
$\theta_1,\ldots,\theta_N \in \Xi$. Since each $A_i$ consists of at most $K$ intervals, we have that 
\begin{equation}
\label{eq:few_optimality_points_proof}
\card (\cup_{i=1}^n \mathcal B_i) \leq 2 n K. 
\end{equation}
Fix $\epsilon>0$ such that 
\[
\epsilon < \frac{1}{2}\min_{i\neq j} |\theta_i - \theta_j|. 
\]
Since for each $\theta \in \Theta$ we have $S_n(\theta, \epsilon) \to 1$, there exists $n$ large enough such that 
\[
\card \left(S_n(\theta_i, \epsilon) \right) \geq n \left(1-\frac{1}{2N} \right)
\]
for all $i=1,\ldots,N$. However, $S_n(\theta_1,\epsilon), \ldots S_n(\theta_N,\epsilon)$ are disjoint, so the cardinallity of their union is at least $n\left(1-\frac{1}{2N} \right)N$ which is grater than $2nK + n/2$ in contradiction to \eqref{eq:few_optimality_points_proof}. 

