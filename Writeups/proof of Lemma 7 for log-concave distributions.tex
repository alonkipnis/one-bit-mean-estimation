%\documentclass[letterpaper]{IEEEtran}
\documentclass[letterpaper, conference]{IEEEtran}      % Use this line for a4 paper
%\IEEEoverridecommandlockouts                              %

%\usepackage{mathcomSTEP}

%\overrideIEEEmargins 
%\IEEEoverridecommandlockouts                              % This command is only needed if 
% you want to use the \thanks command

%\overrideIEEEmargins                                      % Needed to meet printer requirements.

% See the \addtolength command later in the file to balance the column lengths
% on the last page of the document

\usepackage{mathptmx} 
\usepackage{times} 
\usepackage{amsmath} 
\usepackage{amsbsy} 
\usepackage{amssymb}
%\usepackage{newtxtext, newtxmath}
\usepackage{mathrsfs}
\usepackage{comment}
\usepackage[export]{adjustbox}
\usepackage{tikz}
\usetikzlibrary{external,positioning,decorations.pathreplacing,shapes,arrows,patterns}

%\tikzexternalize[mode=list and make]
\usepackage{algorithmicx}
\usepackage{pgfplots}
\usepackage{graphicx}
\usepackage{pstool}
\usepackage[latin1]{inputenc}
\usetikzlibrary{arrows,shapes}
\usepackage{xifthen}
\usepackage{epic}
\usepackage{caption}
\usepackage{epstopdf}

\newtheorem{thm}{\bf{Theorem}}
\newtheorem{cor}[thm]{\bf {Corollary}}
\newtheorem{lem}[thm]{\bf {Lemma}}
\newtheorem{prop}[thm]{\bf {Proposition}}
\newtheorem{example}{\bf {Example}}
\newtheorem{definition}{\bf {Definition}}
\newtheorem{rem}{\bf {Remark}}

\newcommand{\mmse}{\mathsf{mmse}}
\newcommand{\supp}{\mathrm{supp} }
\renewcommand\vec[1]{\ensuremath\boldsymbol{#1}}
\newenvironment{proof}{\paragraph*{Proof}}{\hfill$\square$ \newline}
\newcommand{\sgn}{\mathrm{sgn} }
\newcommand{\argmax}{\mathrm{argmax}}
\newcommand*{\QEDA}{\hfill\ensuremath{\square}}


\tikzstyle{int}=[draw, fill=blue!10, minimum height = 1cm, minimum width=1.5cm,thick ]
\tikzstyle{sint}=[draw, fill=blue!10, minimum height = 0.5cm, minimum width=0.8cm,thick ]
\tikzstyle{sum}=[circle, fill=blue!10, draw=black,line width=1pt,minimum size = 0.5cm, thick ]
\tikzstyle{ssum}=[circle, fill=blue!10,draw=black,line width=1pt,minimum size = 0.1cm]
\tikzstyle{int1}=[draw, fill=blue!10, minimum height = 0.5cm, minimum width=1cm,thick ]
\tikzstyle{enc}=[draw, fill=blue!10, minimum height = 2.7cm, minimum width=1cm,thick ]
\tikzstyle{int}=[draw, fill=blue!10, minimum height = 1cm, minimum width=1.5cm,thick ]


\title{\LARGE \bf Mean Estimation from Adaptive One-bit Measurements}
%
\author{
\IEEEauthorblockN{Alon Kipnis}
\IEEEauthorblockA{Department of Electrical Engineering \\
Stanford University\\
Stanford, CA\\}
\and
\IEEEauthorblockN{John C. Duchi}
\IEEEauthorblockA{Department of Electrical Engineering \\
and Department of Statistics \\
Stanford University\\
Stanford, CA\\}
}

\begin{document}

\begin{lem} \label{lem:bound_intervals}
Assume that $X_1,\ldots,X_n$ are distributed with CDF $F(x)$ and PDF $f(x)$ such that $F(-x) = 1-F(x)$ (and $f(-x)=f(x)$). Assume moreover that 
$ f(x) = e^{g(x}}$ where $g(x)$ is concave and twice differentiable such that $g''(x)<0$. Then for any $x_1 \geq \ldots \geq x_n \in \mathbb R$, we have 
\begin{equation}
\frac{ \left(  \sum_{k=1}^n (-1)^{k+1} f(x_k) \right)^2} 
{\left( \sum_{k=1}^n (-1)^{k+1} F(x_k) \right)\left(1- \sum_{k=1}^n (-1)^{k+1} F(x_k) \right)  } \leq \frac{2} {\pi}. \label{eq:bound_intervals}
\end{equation}
\end{lem}

\subsubsection*{Proof of Lem.~\ref{lem:bound_intervals}}We use induction on $n \in \mathbb N$. For the base case $n=1$ we have 
\begin{equation} \label{eq:induction_base}
\frac{  f^2(x)} 
{F(x) \left(1 - F(x) \right) }.
\end{equation}
Since $f(x)$ is log-concave, so does $F(x)$. We now write $F(x) = e^{h(x)}$ with $h(x)$ concave. Note that $f(x) = h'(x) e^{h(x)}$, $h'(x)\geq 0$, $f(x) = f(-x) = h'(-x)e^{h(-x)} $, and $h''(x)\leq 0$ ($h(x)$ is twice differentiable since $F(x)$ is twice differentiable). 
Taking the logarithm of \eqref{eq:induction_base} leads to 
\begin{align*}
& 2 \log f(x) - \log F(x) + \log F(-x) \\
& = 2 \log h'(x) + h(x) + h(-x).
\end{align*}
Since $h'(x)$ is non-increasing, the maximal value of \eqref{eq:induction_base} is obtained as 
{HERE!! \color{red} finish proof by showing that \eqref{eq:induction_base} is smaller than $4f(0)$.\\
}
\\
Assume now that \eqref{eq:bound_intervals} holds for all integers up to some $n = N-1$ and consider the case $n = N$. The maximal value of \eqref{eq:bound_intervals} is attained for the same $(x_1,\ldots,x_N) \in \mathbb R^N$ that attains the maximal value of 
\begin{align*}
& g(x_1,\ldots, x_N) \triangleq 2 \log \left(  \sum_{k=1}^{N} (-1)^{k+1} f(x_k) \right) - \\
&  \log
\left( \sum_{k=1}^N (-1)^{k+1} F(x_k) \right)
-\log \left(1 -  \sum_{k=1}^N (-1)^{k+1} F(x_k) \right) \\
& = 2 \log \delta_N - \log \Delta_N - \log \left(1 - \Delta_N  \right),
\end{align*}
where we denoted $\delta_N \triangleq \sum_{k=1}^{N} (-1)^{k+1} f(x_k)$ and $\Delta_N =  \sum_{k=1}^N (-1)^{k+1} F(x_k)$. The derivative of $g(x_1,\ldots,x_N)$ with respect to $x_k$ is given by
\[
\frac{\partial  g}{\partial x_k} = \frac{2 (-1)^{k+1} f'(x_k)}{\delta_N} -\frac{(-1)^{k+1} f(x_k)}{\Delta_N } + \frac{(-1)^{k+1} \phi(x_k)}{1-\Delta_N }.
\]
We conclude that the gradient of $g$ vanishes only if
\[
\frac{f'(x_k)}{f(x_k)} = g'(x_k) = \frac{\delta_N}{2} \left( \frac{1}{\Delta_N} - \frac{1}{1-\Delta_N} \right),\quad k=1,\ldots,N.
\]
Due to our assumption that $g''(x) < 0$, the function $g'(x)$ is strictly decreasing. As a result, $g'(x)$ is one to one and the condition above implies $x_1 = \ldots = x_N$. If $N$ is odd then for $x_1=\ldots =x_N$ we have that the LHS of \eqref{eq:bound_intervals} equals
\[
\frac{f(x_1)^2}{ F(x_1) (1 - F(x_1))},
\]
which was shown to be smaller than $4f^2(0)$. If $N$ is even, then for any constant $c$ the limit of the LHS of \eqref{eq:bound_intervals} as $(x_1,\ldots,x_N)\rightarrow (c,\ldots,c)$ exists and equals zero. Therefore, the maximum of the LHS of \eqref{eq:bound_intervals} is not attained at the line $x_1=\ldots=x_N)$. We now consider the possibility that the LHS of \eqref{eq:bound_intervals} is maximized at the borders, as one or more of the coordinates of $(x_1,\ldots,x_N)$ approaches plus or minus infinity. For simplicity we only consider the cases where $x_N$ goes to minus infinity or $x_1$ goes to plus infinity (the general case where the first $m$ coordinates goes to infinity or the last $m$ to minus infinity is obtained using similar arguments). Assume first $x_N \rightarrow -\infty$. Then the LHS of \eqref{eq:bound_intervals} equals
\begin{align*}
\frac{ \left(  \sum_{k=1}^{N-1} (-1)^{k+1}f(x_k) \right)^2} 
{\left( \sum_{k=1}^{N-1} (-1)^{k+1} F(x_k) \right)\left(1- \sum_{k=1}^{N-1} (-1)^{k+1} F(x_k)  \right) } ,
\end{align*}
which is smaller than $2/\pi$ by the induction hypothesis. Assume now that $x_1 \rightarrow \infty$. Then the LHS of
\eqref{eq:bound_intervals} equals
\begin{align*}
& \frac{ \left(  \sum_{k=2}^{N} (-1)^{k+1}f(x_k) \right)^2} 
{\left( 1 + \sum_{k=2}^{N} (-1)^{k+1} F(x_k) \right)\left(1- 1 - \sum_{k=2}^{N} (-1)^{k+1} F(x_k)  \right) }  \\
& = \frac{ \left(  -\sum_{m=1}^{N} (-1)^{m+1}f(x'_m) \right)^2} 
{\left( 1 - \sum_{m=1}^{N-1} (-1)^{m+1} F(x'_{m}) \right)\left( \sum_{m=1}^{N-1} (-1)^{m+1} F(x'_{m})  \right) },
\end{align*}
where $x'_{m} = x_{m+1}$. The last expression is also smaller than $4f(0)$ by the induction hypothesis. This proves Lem.~\ref{lem:bound_intervals}. \\

\subsubsection*{Proof of Lem.~\ref{lem:fisher_bound}}
The Fisher information of $M$ with respect to $\theta$ is given by
\begin{align}
I_\theta & =  \mathbb E \left[ \left( \frac{d}{d\theta} \log P\left( M | \theta \right) \right)^2 |\theta \right] \nonumber \\
& = \frac{ \left(\frac{d}{d\theta} P(M=1|\theta) \right)^2}{P(M=1| \theta)} + \frac{ \left(\frac{d}{d\theta} P(M=-1|\theta) \right)^2} {P(M=-1| \theta)} \nonumber \\
& =  \frac{ \left( \frac{d}{d\theta} \int_A \phi \left( \frac{x-\theta}{\sigma} \right)dx \right)^2} { P(M=1| \theta) } + \frac{ \left( \frac{d}{d\theta}\int_A \phi \left( \frac{x-\theta}{\sigma} \right)dx \right)^2} { P(M=-1| \theta) } \nonumber \\ 
& \overset{(a)}{=} \frac{ \left( - \int_A \phi' \left( \frac{x-\theta}{\sigma} \right)dx \right)^2} {\sigma^2 P(M=1| \theta) } + \frac{ \left(- \int_A \phi' \left( \frac{x-\theta}{\sigma} \right)dx \right)^2} { \sigma^2P(M=-1| \theta) } \nonumber \\ 
& = \frac{\left( \int_A \phi'\left( \frac{x-\theta}{\sigma} \right) dx \right)^2 }{  \sigma^2 P(M=1 | \theta) \left(1-P(M=1|\theta) \right)  }, \nonumber \\
& = \frac{\left( \int_A \phi'\left( \frac{x-\theta}{\sigma} \right) dx \right) \left( \int_A \phi'\left( \frac{x-\theta}{\sigma} \right) dx \right)}{  \sigma^2 \left( \int_A \phi \left( \frac{x-\theta}{\sigma} \right) dx \right)  \left(1- \int_A \phi \left( \frac{x-\theta}{\sigma} \right) dx \right) }, \label{eq:lem_fisher_bound_proof1}
\end{align}
where differentiation under the integral sign in $(a)$ is possible since $\phi(x)$ is differentiable with absolutely integrable derivative $\phi'(x) = -x\phi(x)$. Regularity of the Lebesgue measure implies that for any $\epsilon>0$, there exists a finite number $k$ of disjoint open intervals $I_1,\ldots I_k$ such that 
\[
\int_{A\setminus \cup_{j=1}^k I_j }  dx < \epsilon \sigma^2,
\]
which implies that for any $\epsilon' > 0$, the set $A$ in \eqref{eq:lem_fisher_bound_proof1} can be replaced by a finite union of disjoint intervals without increasing $I_\theta$ by more than $\epsilon'$. It is therefore enough to proceed in the proof assuming that $A$ is of the form
\[
A = \cup_{j=1}^k (a_j,b_j),
\]
with $\infty \leq a_1 \leq \ldots a_k$, $b_1 \leq b_k \leq \infty$ and $a_j \leq b_j$ for $j=1,\ldots,k$. Under this assumption we have
\begin{align*}
\mathbb P(M_n=1| \theta) & = \sum_{j=1}^k \mathbb P\left(X_n \in (a_j,b_j) \right)  \\
& = \sum_{j=1}^k \left( \Phi \left(\frac{b_j-\theta}{\sigma} \right) -  \Phi \left(\frac{a_j-\theta}{\sigma} \right)  \right),
\end{align*}
so \eqref{eq:lem_fisher_bound_proof1} can be rewritten as
\begin{align}
& =   \frac { \left( \sum_{j=1}^{k} \phi \left(\frac{a_j-\theta}{\sigma} \right) - \phi \left( \frac{b_j-\theta} {\sigma} \right)  \right)^2 } 
{\sigma^2 \left( \sum_{j=1}^k \Phi \left( \frac{b_j-\theta }{\sigma}\right) - \Phi \left( \frac{a_j-\theta }{\sigma}\right)  \right) }  \nonumber \\
& \times \frac {1} 
{1- \left( \sum_{j=1}^k \Phi \left( \frac{b_j-\theta }{\sigma}\right) - \Phi \left( \frac{a_j-\theta }{\sigma}\right)  \right) } 
\label{eq:lemma_J}
\end{align}
It follows from Lem.~\ref{lem:bound_intervals} that for any $\theta \in \mathbb R$ and any choice of the intervals endpoints, \eqref{eq:lemma_J} is smaller than $2/(\sigma^2 \pi)$. Therefore, the proof of  Lem.~\ref{lem:fisher_bound} is now completed.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\bibliographystyle{IEEEtran}
\bibliography{IEEEabrv,/Users/Alon1/LaTex/bibtex/sampling}


\end{document}
